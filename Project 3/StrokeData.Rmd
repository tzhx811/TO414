---
title: "Predicting Stroke"
author: "Evan Jiang, Anthony Zhao, Jenny Yu, Xincheng Yuan, Yusuf Uzhunnan"
date: "4/25/2021"
output: 
  html_document:
      toc: true
      toc_float: true
      theme: readable
      highlight: tango
      code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Talk about business content (ie less flase negatives given death)
## Mention that some models dont handle inbalanced data well and talk about why it is predicting all ones or zeros (ie smaller data whens split, age just doesnt see many strokes)

## Intro
In this project, we are attempting to accurate predict if a patient will have a stroke or not based on input variables such as age, gender, BMI, hypertension, glucose level, etc. We were originally attracted to this data set because it involves discovering practical insights that might ultimately lead to saving someone's life. A stroke is a scary event for someone to go through, so by creating predictive models, we hope to get a better insight on not only which variables have the strongest effect on a patient's probability of having a stroke, but also which variables are most significant to target when trying to prevent a risk of stroke. While somewhat rare, the effects of having a stroke can be life-changing. We believe that there are two main business applications to this project. The first is the most obvious connection: saving lives. Whether it be a family medicine doctor or an emergency room respondent, knowing how certain variables interact with the chance of stroke can lead to better prescriptions, better service, and more lives saved. The second business application is less obvious, but still quite relevant: insurance agencies. Insurance agencies can take the information of the patient, input it into the models created, and see the chance of stroke that the client may have. This can go into their modeling of medical insurance packages as well as the the placement of the client within the packages' different level of coverage and risk premium. 
<p> Next, we will start by loading and cleaning the data so it is prepared for analysis. From there, we will be creating different graphs and visuals to see if certain input variables interact with each other or have a stronger interaction force with the response variable (stroke or not). If any strong correlations are discovered from the data visualization section, we will take note and implement different train and test splits on top of our general models. After data visualization, we start to create the general models: SVM, Decision Tree, KNN, Logistic Regression, and ANN. Within each of these model chunks, we will create a final model that involves all the variables, but broken into a normalized train and test split, and a confusion matrix that compares the model's prediction to the test data. From there, we will also run more models and confusion matrices on different categorical splits. Some examples may be: married versus non-married, hypertension versus non-hypertension, whatever is discovered from the beginnings of our researching in data visualization. Ultimately, we will end with a stacked model that combines the predictions from our main general models and makes a prediction from those by assigning weights to the individual models' predictions. Once the stacked model is made, we will improve it using the train() command learned in class. This will be paired with a confusion matrix of which we can compare performance statistics between the individual models and the stacked model. We will end with a summary of our findings. 

## Library Loading
```{r, warning=FALSE}
library(C50)
library(class)
library(gmodels)
library(caret)
library(lmtest)
library(aod)
library(VGAM)
library(neuralnet)
library(kernlab)
library(lsr)
```


## Load in Data
```{r}
stroke <- read.csv("healthcare-dataset-stroke-data.csv")
stroke <- stroke[stroke$gender != "Other",]
stroke$id <- NULL
stroke$gender <- as.factor(stroke$gender)
stroke$work_type <- as.factor(stroke$work_type)
stroke$smoking_status <- as.factor(stroke$smoking_status)
stroke$ever_married <- as.factor(stroke$ever_married)
stroke$Residence_type <- as.factor(stroke$Residence_type)
summary(stroke)
```


## Create Linear Model to Predict Missing BMI
```{r}
# create the bmi data that doesn't have NA
bmi_data <- stroke[stroke$bmi != "N/A",]
# can't use stroke to predict bmi
bmi_model <- lm(bmi ~ .-stroke, data = bmi_data)
summary(bmi_model)
# remove insignificant variables
bmi_model <- lm(bmi ~ .-stroke-gender-Residence_type+age*hypertension*ever_married-heart_disease, data = bmi_data)
summary(bmi_model)

stroke$bmi[stroke$bmi == "N/A"] = predict(bmi_model, stroke[stroke$bmi == "N/A",])
stroke$bmi <- as.numeric(stroke$bmi)
```

### Define Helper Functions
```{r}
set.seed(42)

normalize <- function(x) {
  if(max(x) - min(x) == 0){
    return (x)
  }
  return ((x - min(x)) / (max(x) - min(x)))
}

set_splits <- function(x, norm) {
  if(norm){
    x = as.data.frame(lapply(as.data.frame(model.matrix(~.-1,x)), normalize))
  }
  testrows <- sample(1:nrow(x), 0.25*nrow(x))
  return (list(x[-testrows,], x[testrows,]))
}
```

## Visualizations
```{r}
par(mfrow=c(2,2))
barplot(prop.table(table(stroke$stroke, stroke$gender), 2), main="Gender vs Stroke", xlab="Gender", col=c("darkblue","red"))
barplot(prop.table(table(stroke$stroke, stroke$hypertension), 2), main="Hypertension vs Stroke", xlab="Hypertension", col=c("darkblue","red"))
barplot(prop.table(table(stroke$stroke, stroke$heart_disease), 2), main="Heart Disease vs Stroke", xlab="Heart Disease", col=c("darkblue","red"))
barplot(prop.table(table(stroke$stroke, stroke$ever_married), 2), main="Marriage vs Stroke", xlab="Marriage", col=c("darkblue","red"))
par(mfrow=c(2,2))
barplot(prop.table(table(stroke$stroke, stroke$work_type), 2), main="Work vs Stroke", xlab="Work", col=c("darkblue","red"))
barplot(prop.table(table(stroke$stroke, stroke$Residence_type), 2), main="Residence vs Stroke", xlab="Residence Type", col=c("darkblue","red"))
barplot(prop.table(table(stroke$stroke, stroke$smoking_status), 2), main="Smoker vs Stroke", xlab="Smoking Status", col=c("darkblue","red"))
barplot(prop.table(table(stroke$stroke, quantileCut(stroke$age, 10)), 2), main="Age vs Stroke", xlab="Age", col=c("darkblue","red"))
par(mfrow=c(2,2))
barplot(prop.table(table(stroke$stroke, quantileCut(stroke$bmi, 10)), 2), main="BMI vs Stroke", xlab="BMI", col=c("darkblue","red"))
barplot(prop.table(table(stroke$stroke, quantileCut(stroke$avg_glucose_level, 10)), 2), main="Glucose vs Stroke", xlab="Glucose Level", col=c("darkblue","red"))
```


### Inter-Variable Visualization
```{r}
prop.table(table(stroke$ever_married, stroke$hypertension), 1)
prop.table(table(stroke$ever_married, stroke$heart_disease), 1)
prop.table(table(stroke$hypertension, stroke$heart_disease), 1)
par(mfrow=c(2,2))
barplot(prop.table(table(stroke$ever_married, quantileCut(stroke$age, 10)), 2), main="Age vs Marriage", xlab="Age", col=c("darkblue","red"))
barplot(prop.table(table(stroke$hypertension, quantileCut(stroke$age, 10)), 2), main="Age vs Hypertension", xlab="Age", col=c("darkblue","red"))
barplot(prop.table(table(stroke$heart_disease, quantileCut(stroke$age, 10)), 2), main="Age vs Heart Disease", xlab="Age", col=c("darkblue","red"))
par(mfrow=c(2,2))
barplot(prop.table(table(stroke$heart_disease[stroke$ever_married=="Yes"], cut(stroke$age[stroke$ever_married=="Yes"], breaks = c(0,10,20,30,40,50,60,70,80,90))), 2), main="Age vs Heart Disease for Married", xlab="Age", col=c("darkblue","red"))
barplot(prop.table(table(stroke$heart_disease[stroke$ever_married=="No"], cut(stroke$age[stroke$ever_married=="No"], breaks = c(0,10,20,30,40,50,60,70,80,90))), 2), main="Age vs Heart Disease for Unmarried", xlab="Age", col=c("darkblue","red"))
barplot(prop.table(table(stroke$hypertension[stroke$ever_married=="Yes"], cut(stroke$age[stroke$ever_married=="Yes"], breaks = c(0,10,20,30,40,50,60,70,80,90))), 2), main="Age vs Hypertension for Married", xlab="Age", col=c("darkblue","red"))
barplot(prop.table(table(stroke$hypertension[stroke$ever_married=="No"], cut(stroke$age[stroke$ever_married=="No"], breaks = c(0,10,20,30,40,50,60,70,80,90))), 2), main="Age vs Hypertension for Unmarried", xlab="Age", col=c("darkblue","red"))

```

## Create Splits
```{r}
general_norm <- set_splits(stroke, norm = TRUE)
age_young_data_norm = set_splits(stroke[stroke$age<=55,], norm = TRUE)
age_old_data_norm = set_splits(stroke[stroke$age>55,], norm = TRUE)
bmi_risk_data_norm = set_splits(stroke[stroke$bmi>26.5 & stroke$bmi<32,], norm = TRUE)
bmi_safe_data_norm = set_splits(stroke[stroke$bmi<=26.5 | stroke$bmi>=32,], norm = TRUE)
```

## SVM Model
```{r}
stroke_svm <- ksvm(stroke ~ ., data = general_norm[[1]], kernel = "rbfdot")
svm_pred <- predict(stroke_svm, general_norm[[2]])
cutoff = quantile(svm_pred, 1-mean(general_norm[[1]]$stroke))
svm_pred = ifelse(svm_pred>cutoff, 1, 0)
confusionMatrix(as.factor(svm_pred), as.factor(general_norm[[2]]$stroke))
```

### SVM Age Based Model
```{r}
# first is young model
young_svm <- ksvm(stroke ~ ., data = age_young_data_norm[[1]], kernel = "rbfdot")
young_pred <- predict(young_svm, age_young_data_norm[[2]])
cutoff = quantile(young_pred, 1-mean(age_young_data_norm[[1]]$stroke))
young_pred = ifelse(young_pred>cutoff, 1, 0)
# now old model
old_svm <- ksvm(stroke ~ ., data = age_old_data_norm[[1]], kernel = "rbfdot")
old_pred <- predict(old_svm, age_old_data_norm[[2]])
cutoff = quantile(old_pred, 1-mean(age_old_data_norm[[1]]$stroke))
old_pred = ifelse(old_pred>cutoff, 1, 1)

# now combine them together
combined_svmage_pred = c(young_pred, old_pred)
# get the true labels
true_label = c(age_young_data_norm[[2]]$stroke, age_old_data_norm[[2]]$stroke)
confusionMatrix(as.factor(combined_svmage_pred), as.factor(true_label))
```

### SVM BMI Based Model
```{r}
risk_svm <- ksvm(stroke ~ ., data = bmi_risk_data_norm[[1]], kernel = "rbfdot")
risk_pred <- predict(risk_svm, bmi_risk_data_norm[[2]])
cutoff = quantile(risk_pred, 1-mean(bmi_risk_data_norm[[1]]$stroke))
risk_pred = ifelse(risk_pred>cutoff, 1, 0)

safe_svm <- ksvm(stroke ~ ., data = bmi_safe_data_norm[[1]], kernel = "rbfdot")
safe_pred <- predict(safe_svm, bmi_safe_data_norm[[2]])
cutoff = quantile(safe_pred, 1-mean(bmi_safe_data_norm[[1]]$stroke))
safe_pred = ifelse(safe_pred>cutoff, 1, 0)

combined_svmbmipred = c(risk_pred, safe_pred)
true_label = c(bmi_risk_data_norm[[2]]$stroke, bmi_safe_data_norm[[2]]$stroke)
confusionMatrix(as.factor(combined_svmbmipred), as.factor(true_label))
```

## Decision Tree
```{r}

#rebalance errors - want to prioritize minimizing false negatives, if people are at risk of stroke we want to know, used 20 to make it about 20% of true positives show up as negatives 
error_cost <- matrix(c(0, 1, 20, 0), nrow = 2)

#build decision tree
stroke_dt <- C5.0(as.factor(stroke) ~ ., data = general_norm[[1]], costs = error_cost)

plot(stroke_dt)
summary(stroke_dt)

#predict the test data
stroke_dt_pred <- predict(stroke_dt, general_norm[[2]])
CrossTable(general_norm[[2]]$stroke, stroke_dt_pred)

# Confusion Matrix and Kappa Statistics


confusionMatrix(stroke_dt_pred, as.factor(general_norm[[2]]$stroke))
```

### Decision Trees Age Based Model
```{r}

summary(age_old_data_norm[[1]])
#Young Patients
ageYoung_dt <- C5.0(as.factor(stroke) ~ ., data = age_young_data_norm[[1]], costs = error_cost)
plot(ageYoung_dt)
summary(ageYoung_dt)

#predict the test data
ageYoung_dt_pred <- predict(ageYoung_dt, age_young_data_norm[[2]])


#Old Patients
ageOld_dt <- C5.0(as.factor(stroke) ~ ., data = age_old_data_norm[[1]], costs = error_cost)
plot(ageOld_dt)
summary(ageOld_dt)

#predict the test data
ageOld_dt_pred <- predict(ageOld_dt, age_old_data_norm[[2]])


#Combined confusion matrix
combinedagepredict <- c(ageOld_dt_pred,ageYoung_dt_pred)-1
summary(combinedagepredict)

combinedageactual <- c(age_old_data_norm[[2]]$stroke, age_young_data_norm[[2]]$stroke)
summary(combinedageactual)

confusionMatrix(as.factor(combinedagepredict), as.factor(combinedageactual))
```

### Decision Trees BMI Based Model
```{r}
# separate data for further insight

#Risky BMI Patients

bmiRisk_dt <- C5.0(as.factor(stroke) ~ ., data = bmi_risk_data_norm[[1]], costs = error_cost)
plot(bmiRisk_dt)
summary(bmiRisk_dt)

#predict the test data
bmiRisk_dt_pred <- predict(bmiRisk_dt, bmi_risk_data_norm[[2]])


#Not Risky BMI Patients

bmiNotRisk_dt <- C5.0(as.factor(stroke) ~ ., data = bmi_safe_data_norm[[1]], costs = error_cost)
plot(bmiNotRisk_dt)
summary(bmiNotRisk_dt)

#predict the test data
bmiNotRisk_dt_pred <- predict(bmiNotRisk_dt, bmi_safe_data_norm[[2]])

#Combined confusion matrix
combinedbmipredict <- c(bmiNotRisk_dt_pred,bmiRisk_dt_pred)-1
summary(combinedbmipredict)

combinedbmiactual <- c(bmi_safe_data_norm[[2]]$stroke, bmi_risk_data_norm[[2]]$stroke)
summary(combinedbmiactual)

confusionMatrix(as.factor(combinedbmipredict), as.factor(combinedbmiactual))
```

## KNN Model
```{r}
set.seed(12345)
stroketrain_knn <- general_norm[[1]]
stroketest_knn <- general_norm[[2]]

knn_train_labels <- general_norm[[1]]$stroke
knn_test_labels <- general_norm[[2]]$stroke

stroke_knn_test_pred <- knn(train = stroketrain_knn, test = stroketest_knn,
                      cl = knn_train_labels, k= sqrt(sqrt(nrow(general_norm[[1]]))))

confusionMatrix(as.factor(stroke_knn_test_pred), as.factor(knn_test_labels))
```

### KNN Model Age Based Model
```{r}
###Young patients
stroketrain_knn_young <- age_young_data_norm[[1]]
stroketest_knn_young <- age_young_data_norm[[2]]
knn_train_labels_young <- age_young_data_norm[[1]]$stroke
knn_test_labels_young <- age_young_data_norm[[2]]$stroke

stroke_knn_pred_young <- knn(train = stroketrain_knn_young, test = stroketest_knn_young,
                      cl = knn_train_labels_young, k= sqrt(sqrt(nrow(stroketrain_knn_young))))
confusionMatrix(as.factor(stroke_knn_pred_young), as.factor(knn_test_labels_young))

###Old patients
stroketrain_knn_old <- age_old_data_norm[[1]]
stroketest_knn_old <- age_old_data_norm[[2]]
knn_train_labels_old <- age_old_data_norm[[1]]$stroke
knn_test_labels_old <- age_old_data_norm[[2]]$stroke

stroke_knn_pred_old <- knn(train = stroketrain_knn_old, test = stroketest_knn_old,
                      cl = knn_train_labels_old, k = sqrt(sqrt(nrow(stroketrain_knn_old))))
confusionMatrix(as.factor(stroke_knn_pred_old), as.factor(knn_test_labels_old))

##Combined
knn_age_combined_pred = c(stroke_knn_pred_young, stroke_knn_pred_old) - 1
true_label_age = c(age_young_data_norm[[2]]$stroke, age_old_data_norm[[2]]$stroke)
confusionMatrix(as.factor(knn_age_combined_pred), as.factor(true_label_age))
```

### KNN Model BMI Based Model
```{r}
###Risky patients
stroketrain_knn_risk <- bmi_risk_data_norm[[1]]
stroketest_knn_risk <- bmi_risk_data_norm[[2]]
knn_train_labels_risk <- bmi_risk_data_norm[[1]]$stroke
knn_test_labels_risk <- bmi_risk_data_norm[[2]]$stroke

stroke_knn_pred_risk <- knn(train = stroketrain_knn_risk, test = stroketest_knn_risk,
                      cl = knn_train_labels_risk, k= sqrt(sqrt(nrow(stroketrain_knn_risk))))
confusionMatrix(as.factor(stroke_knn_pred_risk), as.factor(knn_test_labels_risk))

###Safe patients
stroketrain_knn_safe <- bmi_safe_data_norm[[1]]
stroketest_knn_safe <- bmi_safe_data_norm[[2]]
knn_train_labels_safe <- bmi_safe_data_norm[[1]]$stroke
knn_test_labels_safe <- bmi_safe_data_norm[[2]]$stroke

stroke_knn_pred_safe <- knn(train = stroketrain_knn_safe, test = stroketest_knn_safe,
                      cl = knn_train_labels_safe, k = sqrt(sqrt(nrow(stroketrain_knn_safe))))
confusionMatrix(as.factor(stroke_knn_pred_safe), as.factor(knn_test_labels_safe))

##Combined
knn_bmi_combined_pred = c(stroke_knn_pred_risk, stroke_knn_pred_safe) - 1
true_label_bmi = c(bmi_risk_data_norm[[2]]$stroke, bmi_safe_data_norm[[2]]$stroke)
confusionMatrix(as.factor(knn_bmi_combined_pred), as.factor(true_label_bmi))
```

## Logistic Regression Model
```{r}
#Mass Effect
MassEffect <- glm(stroke ~ ., data = general_norm[[1]], family = "binomial")
summary(MassEffect)

#Final
logit_final <- step(MassEffect)
summary(logit_final)

#Confusion Matrix (.11 gave the highest kappa statistic)
LogReg_Pred = predict(logit_final, newdata = general_norm[[2]], type = "response")
LogReg_Pred = ifelse(LogReg_Pred>.11, 1, 0)
confusionMatrix(data = as.factor(LogReg_Pred), reference = as.factor(general_norm[[2]]$stroke))
```

### Logistic Regression Age Based Model
```{r}
#Young
masslogmodel_young <- glm(stroke ~., data = age_young_data_norm[[1]], family = "binomial")
summary(masslogmodel_young)

finallogmodel_young <- step(masslogmodel_young)
summary(finallogmodel_young)

young_Logpred <- predict(finallogmodel_young, age_young_data_norm[[2]], type= "response")
young_Logpred = ifelse(young_Logpred>.0002, 0, 1)

#Old
masslogmodel_old <- glm(stroke ~., data = age_old_data_norm[[1]], family = "binomial")
summary(masslogmodel_old)

finallogmodel_old <- step(masslogmodel_old)
summary(finallogmodel_old)

old_Logpred <- predict(finallogmodel_old, age_old_data_norm[[2]], type= "response")
old_Logpred = ifelse(old_Logpred>.45, 0, 1)

#Combine Predictions (The thresholds above gave us the highest kappa statistic)
age_combined_Logpred = c(young_Logpred, old_Logpred)

age_true_label = c(age_young_data_norm[[2]]$stroke, age_old_data_norm[[2]]$stroke)

confusionMatrix(as.factor(age_combined_Logpred), as.factor(age_true_label))


```

### Logistic Regression BMI Based Models
```{r}
#Risk
masslogmodel_risk <- glm(stroke ~., data = bmi_risk_data_norm[[1]], family = "binomial")
summary(masslogmodel_risk)

finallogmodel_risk <- step(masslogmodel_risk)
summary(finallogmodel_risk)

risk_Logpred <- predict(finallogmodel_risk, bmi_risk_data_norm[[2]], type= "response")
risk_Logpred = ifelse(risk_Logpred>.4, 0, 1)

#Safe
masslogmodel_safe <- glm(stroke ~., data = bmi_safe_data_norm[[1]], family = "binomial")
summary(masslogmodel_safe)

finallogmodel_safe <- step(masslogmodel_safe)
summary(finallogmodel_safe)

safe_Logpred <- predict(finallogmodel_safe, bmi_safe_data_norm[[2]], type= "response")
safe_Logpred = ifelse(safe_Logpred>.0004, 0, 1)

#Combine Predictions (The thresholds above gave us the highest kappa statistic)
bmi_combined_Logpred = c(risk_Logpred, safe_Logpred)

bmi_true_label = c(bmi_risk_data_norm[[2]]$stroke, bmi_safe_data_norm[[2]]$stroke)

confusionMatrix(as.factor(bmi_combined_Logpred), as.factor(bmi_true_label))
```

## ANN Model
```{r cache = TRUE}

ANNmodel <- neuralnet(general_norm[[1]]$stroke ~ ., data=general_norm[[1]],hidden =2, stepmax = 1000000)
plot(ANNmodel, rep = "best")

# obtain model results
ann_results <- compute(ANNmodel, general_norm[[2]])
ann_predicted_stroke <- ann_results$net.result
ann_predicted_stroke <- ifelse(ann_predicted_stroke >= 0.5, 1,0)

confusionMatrix(as.factor(ann_predicted_stroke), as.factor(general_norm[[2]]$stroke))


```

### ANN Age Based Model
```{r cache = TRUE}
#Young
ANNyoungmodel <- neuralnet(age_young_data_norm[[1]]$stroke ~ ., data=age_young_data_norm[[1]],hidden =2)
plot(ANNyoungmodel, rep = "best")

# obtain model results
annageyoung_results <- compute(ANNyoungmodel, age_young_data_norm[[2]])
predicted_strokeyoung <- annageyoung_results$net.result
predicted_strokeyoung <- ifelse(predicted_strokeyoung >= 0.5, 1,0)

# Accuracy, Kappa, etc.
confusionMatrix(as.factor(predicted_strokeyoung), as.factor(age_young_data_norm[[2]]$stroke))


#Old
ANNoldmodel <- neuralnet(age_old_data_norm[[1]]$stroke ~ ., data=age_old_data_norm[[1]],hidden =2)
plot(ANNoldmodel, rep = "best")

# obtain model results
annageold_results <- compute(ANNoldmodel, age_old_data_norm[[2]])
predicted_strokeold <- annageold_results$net.result
predicted_strokeold <- ifelse(predicted_strokeold >= 0.5, 1,0)

# Accuracy, Kappa, etc.
confusionMatrix(as.factor(predicted_strokeold), as.factor(age_old_data_norm[[2]]$stroke))

#Combined Model
combined_predAge = c(predicted_strokeold, predicted_strokeyoung)
true_label = c(age_old_data_norm[[2]]$stroke, age_young_data_norm[[2]]$stroke)
confusionMatrix(as.factor(combined_predAge), as.factor(true_label))
```


### ANN BMI Based Model
```{r cache = TRUE}
#Risk
ANNriskmodel <- neuralnet(bmi_risk_data_norm[[1]]$stroke ~ ., data=bmi_risk_data_norm[[1]],hidden =2)
plot(ANNriskmodel, rep = "best")

# obtain model results
annbmirisk_results <- compute(ANNriskmodel, bmi_risk_data_norm[[2]])
predicted_strokerisk <- annbmirisk_results$net.result
predicted_strokerisk <- ifelse(predicted_strokerisk >= 0.5, 1,0)

# Accuracy, Kappa, etc.
confusionMatrix(as.factor(predicted_strokerisk), as.factor(bmi_risk_data_norm[[2]]$stroke))


#Safe
ANNsafemodel <- neuralnet(bmi_safe_data_norm[[1]]$stroke ~ ., data=bmi_safe_data_norm[[1]],hidden =2)
plot(ANNsafemodel, rep = "best")

# obtain model results
annbmisafe_results <- compute(ANNsafemodel, bmi_safe_data_norm[[2]])
predicted_strokesafe <- annbmisafe_results$net.result
predicted_strokesafe <- ifelse(predicted_strokesafe >= 0.5, 1,0)

# Accuracy, Kappa, etc.
confusionMatrix(as.factor(predicted_strokesafe), as.factor(bmi_safe_data_norm[[2]]$stroke))

#Combined Model
combined_predbmi= c(predicted_strokerisk, predicted_strokesafe)
true_label = c(bmi_risk_data_norm[[2]]$stroke, bmi_safe_data_norm[[2]]$stroke)
confusionMatrix(as.factor(combined_predbmi), as.factor(true_label))
```

## Stacked Model
```{r}
stackedmodel = data.frame(decision_tree = stroke_dt_pred, ann = ann_predicted_stroke, knn = stroke_knn_test_pred, logistic_reg = LogReg_Pred, svm = svm_pred, Stroke = general_norm[[2]]$stroke)

str(svm_pred)

set.seed(42)

testrows <- sample(1:nrow(stackedmodel),950)
stackedtrain <- stackedmodel[-testrows, ]
stackedtest <- stackedmodel[testrows, ]

stackedmodel$decision_tree <- as.numeric(stackedmodel$decision_tree)
stackedmodel$knn <- as.numeric(stackedmodel$knn)

str(stackedmodel)

# Decision Tree based on Train and Test Split
#build model

stacked_dt <- C5.0(as.factor(Stroke) ~ ., data = stackedtrain, costs = error_cost)

plot(stacked_dt)
summary(stacked_dt)

#predict the test data
stacked_dt_pred <- predict(stacked_dt, stackedtest)

#Evaluate prediction results
confusionMatrix(stacked_dt_pred, as.factor(stackedtest$Stroke))
```

### Stacked Model Age Based Model
```{r}
stackedmodelage = data.frame(decision_tree = combinedagepredict, ann = combined_predAge, knn = knn_age_combined_pred, logistic_reg = age_combined_Logpred, svm = combined_svmage_pred, Stroke = general_norm[[2]]$stroke)

str(stackedmodelage)

set.seed(42)

agetestrows <- sample(1:nrow(stackedmodelage),950)
stackedagetrain <- stackedmodelage[-testrows, ]
stackedagetest <- stackedmodelage[testrows, ]

stackedmodelage$decision_tree <- as.numeric(stackedmodelage$decision_tree)
stackedmodelage$knn <- as.numeric(stackedmodelage$knn)

str(stackedmodelage)

# Decision Tree based on Train and Test Split
#build model

stacked_age_dt <- C5.0(as.factor(Stroke) ~ ., data = stackedagetrain, costs = error_cost)

plot(stacked_age_dt)
summary(stacked_age_dt)

#predict the test data
stacked_age_dt_pred <- predict(stacked_age_dt, stackedagetest)

#Evaluate prediction results
confusionMatrix(stacked_age_dt_pred, as.factor(stackedagetest$Stroke))
```

### Stacked Model BMI Based Model
```{r}
stackedmodelbmi = data.frame(decision_tree = combinedbmipredict, ann = combined_predbmi, knn = knn_bmi_combined_pred, logistic_reg = bmi_combined_Logpred, svm = combined_svmbmipred, Stroke = general_norm[[2]]$stroke)

str(stackedmodelbmi)

set.seed(42)

bmitestrows <- sample(1:nrow(stackedmodelbmi),950)
stackedbmitrain <- stackedmodelbmi[-testrows, ]
stackedbmitest <- stackedmodelbmi[testrows, ]

stackedmodelbmi$decision_tree <- as.numeric(stackedmodelbmi$decision_tree)
stackedmodelbmi$knn <- as.numeric(stackedmodelbmi$knn)

str(stackedmodelbmi)

# Decision Tree based on Train and Test Split
#build model

stacked_bmi_dt <- C5.0(as.factor(Stroke) ~ ., data = stackedbmitrain, costs = error_cost)

plot(stacked_bmi_dt)
summary(stacked_bmi_dt)

#predict the test data
stacked_bmi_dt_pred <- predict(stacked_bmi_dt, stackedbmitest)

#Evaluate prediction results
confusionMatrix(stacked_bmi_dt_pred, as.factor(stackedbmitest$Stroke))
```

## Improved Stacked Model
```{r, warning=FALSE}
set.seed(42)

#Adding Customization Packages
ctrl <- trainControl(method = "cv", number = 10,
                     selectionFunction = "oneSE")

grid <- expand.grid(.model = "tree",
                    .trials = c(1,5,10,15,20,30,35),
                    .winnow = "FALSE")

#Tune the model
TunedStack <- train(as.factor(Stroke) ~ ., data = stackedmodel, method = "C5.0",
           metric = "Kappa",
           trControl = ctrl,
           tuneGrid = grid)
TunedStack

#Preparing data for predict and confusion matrix
stackedtestmm <- as.data.frame(model.matrix(~.-1,stackedtest))
stackedtest_norm <- as.data.frame(lapply(stackedtestmm, normalize))
stackedtest_norm$decision_tree0 <- NULL
names(stackedtest_norm)[names(stackedtest_norm) == "decision_tree1"] <- "decision_tree"
names(stackedtest_norm)[names(stackedtest_norm) == "knn1"] <- "knn"

#Predict and Confusion Matrix
tunedstack_pred <- predict(TunedStack, stackedtest_norm)
confusionMatrix(tunedstack_pred, as.factor(stackedtest_norm$Stroke))
```

### Improved Stacked Model Age Based Model
```{r, warning=FALSE}
set.seed(42)
TunedStackAge <- train(as.factor(Stroke) ~ ., data = stackedmodelage, method = "C5.0",
           metric = "Kappa",
           trControl = ctrl,
           tuneGrid = grid)
TunedStackAge

#Predict and Confusion Matrix
tunedstackAGE_pred <- predict(TunedStackAge, stackedtest_norm)
confusionMatrix(tunedstackAGE_pred, as.factor(stackedtest_norm$Stroke))
```


### Improved Stacked Model BMI Based Model
```{r, warning=FALSE}
set.seed(42)
TunedStackBMI <- train(as.factor(Stroke) ~ ., data = stackedmodelbmi, method = "C5.0",
           metric = "Kappa",
           trControl = ctrl,
           tuneGrid = grid)
TunedStackBMI

#Predict and Confusion Matrix
tunedstackBMI_pred <- predict(TunedStackBMI, stackedtest_norm)
confusionMatrix(tunedstackBMI_pred, as.factor(stackedtest_norm$Stroke))
```

